{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae5d38d0-247b-4ab3-87a4-3d7dbd679d4f",
   "metadata": {},
   "source": [
    "# Final Project Group 52\n",
    "- Guido Takkenberg\n",
    "- Neil Bonnard\n",
    "- Ilyas el Haroui\n",
    "- Luis Blanco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7372a4c-a638-4c00-8861-6c2923189df0",
   "metadata": {},
   "source": [
    "### 0.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aea613e4-daa6-495a-a031-7201bfacb540",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter \n",
    "from nltk.corpus.reader import ConllCorpusReader\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import expit\n",
    "from torch.nn.functional import softmax\n",
    "from datasets import load_dataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import TextClassificationPipeline\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78529d5c-3496-40ac-b36d-7abb4d648973",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ilyas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ilyas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ilyas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64730750-7cba-4365-b698-5f8c57b49521",
   "metadata": {},
   "source": [
    "### 0.2 Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fd2c78c-0714-41c2-9238-18fc39b7c901",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    cleaned_text = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48b5ae28-0e32-4d95-b7a1-f30cd1b94d43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pos_tag_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ad619f-0943-40ab-ba4a-84496594beb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. NERC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7b801b-15b5-43f2-8e60-434167b5b4d9",
   "metadata": {},
   "source": [
    "### 1.1 Train Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b920688a-0fe2-42c5-bda4-ba41255dd077",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_nerc = ConllCorpusReader('./datasets/nerc_dataset/train', 'train.txt', ['words', 'pos', 'ignore', 'chunk'])\n",
    "\n",
    "train_features = []\n",
    "train_gold_labels = []\n",
    "\n",
    "for token, pos, ne_label in train_data_nerc.iob_words():\n",
    "    train_features.append({\"token\": token, \"pos\": pos})\n",
    "    train_gold_labels.append(ne_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36767434-43cf-4497-bc55-f9364e0afa43",
   "metadata": {},
   "source": [
    "### 1.2 Test Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ffac842-29aa-4f3a-b789-349bd43048f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nerc_test_dataset = './datasets/nerc_dataset/test/NER-test.tsv'\n",
    "test_data = pd.read_csv(nerc_test_dataset, sep='\\t', header=0)\n",
    "\n",
    "# Preprocess tokens\n",
    "test_data['preprocessed_token'] = test_data['token'].apply(preprocess_text)\n",
    "\n",
    "# Map from test labels to training labels\n",
    "label_mapping = {\n",
    "    'B-PERSON': 'B-PER',\n",
    "    'I-PERSON': 'I-PER',\n",
    "    'B-ORG': 'B-ORG',\n",
    "    'I-ORG': 'I-ORG',\n",
    "    'B-WORK_OF_ART': 'B-MISC',  \n",
    "    'I-WORK_OF_ART': 'I-MISC',  \n",
    "    'B-DATE': 'B-MISC',  \n",
    "    'I-DATE': 'I-MISC'\n",
    "}\n",
    "\n",
    "test_data['BIO NER tag'] = test_data['BIO NER tag'].map(label_mapping).fillna(test_data['BIO NER tag'])\n",
    "\n",
    "# Apply POS tagging to the token column\n",
    "test_data['POS'] = test_data['token'].apply(lambda x: pos_tag_text(x)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aaf8dc7e-0fbd-4b13-a89e-efec4ed6d2ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_features = []\n",
    "test_gold_labels = []\n",
    "for _, instance in test_data.iterrows():\n",
    "    test_features.append({\"token\": instance['token'], \"pos\": instance['POS']})\n",
    "\n",
    "test_gold_labels = list(test_data['BIO NER tag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22144d36-22a2-497a-b029-0e0cd72073d3",
   "metadata": {},
   "source": [
    "### 1.3 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8a0b2ea-b600-4c69-87f2-4d56e9aea2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "concatenated_data = train_features + test_features\n",
    "\n",
    "vec = DictVectorizer()\n",
    "transformed_vector = vec.fit_transform(concatenated_data)\n",
    "\n",
    "train_features_new = transformed_vector[:len(train_features)]\n",
    "test_features_new = transformed_vector[len(train_features):]\n",
    "\n",
    "lin_clf = svm.LinearSVC()\n",
    "lin_clf.fit(train_features_new, train_gold_labels)\n",
    "\n",
    "predicted_labels = lin_clf.predict(test_features_new)\n",
    "target_names = list(set(train_gold_labels + test_gold_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90e3b35-687d-4a3b-ac81-b8afd0144054",
   "metadata": {},
   "source": [
    "### 1.4 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a0c6375-c6d4-4ec9-9d7e-4c07b214db1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       I-PER       0.00      0.00      0.00         3\n",
      "       I-LOC       0.00      0.00      0.00         0\n",
      "       B-ORG       0.00      0.00      0.00         3\n",
      "           O       0.85      1.00      0.92       160\n",
      "      I-MISC       0.00      0.00      0.00        10\n",
      "       B-LOC       0.00      0.00      0.00         0\n",
      "       I-ORG       0.00      0.00      0.00         6\n",
      "      B-MISC       0.00      0.00      0.00         5\n",
      "       B-PER       1.00      0.33      0.50         6\n",
      "\n",
      "    accuracy                           0.84       193\n",
      "   macro avg       0.21      0.15      0.16       193\n",
      "weighted avg       0.73      0.84      0.78       193\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "unique_labels = set(test_gold_labels + list(predicted_labels))\n",
    "report = classification_report(test_gold_labels, predicted_labels, labels=list(unique_labels), target_names=list(unique_labels))\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7352c2-1777-4bd9-864f-86a3e4145f5a",
   "metadata": {},
   "source": [
    "## 2. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f54807-72ce-43b6-b6e5-b4949e75a9cc",
   "metadata": {},
   "source": [
    "### 2.1 Train data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63f84e81-60fb-4ede-bdb1-b9c191b88c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "\n",
    "sentiment_pipeline = TextClassificationPipeline(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3a47f0-aeca-46ac-a185-e2eb778a7c14",
   "metadata": {},
   "source": [
    "### 2.2 Test data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5171aaa-4448-4c09-89d9-adef0b88e844",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentiment_topic_dataset = './datasets/sentiment_topic_dataset/test/sentiment-topic-test.tsv'\n",
    "sentiment_topic_test_data = pd.read_csv(sentiment_topic_dataset, sep='\\t', header=0)\n",
    "\n",
    "texts = sentiment_topic_test_data['text'].tolist()\n",
    "\n",
    "sentiment_gold_labels = sentiment_topic_test_data['sentiment'].tolist()\n",
    "\n",
    "# Apply preprocessing to each text in the list\n",
    "preprocessed_texts = [preprocess_text(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff901d47-c95f-4a93-bbc1-0aaa54b3bd6b",
   "metadata": {},
   "source": [
    "### 2.3 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5233416-74cf-4b10-8a88-a7f17fa08443",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = sentiment_pipeline(preprocessed_texts)\n",
    "\n",
    "# Map predictions to labels based on the scores\n",
    "predicted_labels = []\n",
    "for prediction in predictions:\n",
    "    label = prediction['label']\n",
    "    if label == 'LABEL_0':\n",
    "        predicted_labels.append('negative')\n",
    "    elif label == 'LABEL_1':\n",
    "        predicted_labels.append('neutral')\n",
    "    elif label == 'LABEL_2':\n",
    "        predicted_labels.append('positive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d42e47c-57e6-46e6-9914-33be65e97ae9",
   "metadata": {},
   "source": [
    "### 2.4 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2f83fe1-3261-4393-8e72-0c9694682f02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.50      0.33      0.40         3\n",
      "    negative       0.50      0.25      0.33         4\n",
      "     neutral       0.33      0.67      0.44         3\n",
      "\n",
      "    accuracy                           0.40        10\n",
      "   macro avg       0.44      0.42      0.39        10\n",
      "weighted avg       0.45      0.40      0.39        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(sentiment_gold_labels, predicted_labels, labels=['positive', 'negative', 'neutral'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf9eca1-475d-4cc9-b389-0aeca20a80a5",
   "metadata": {},
   "source": [
    "## 3. Topic Analysis using 2 systems: Transformer model & Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a04ae6-be91-428b-80a0-681fa4e6440a",
   "metadata": {},
   "source": [
    "### 3.1 BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e3afc4b5-d527-4821-aab3-b9a9f6919e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"cardiffnlp/tweet-topic-latest-multi\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "class_mapping = model.config.id2label\n",
    "\n",
    "predicted_topics = []\n",
    "\n",
    "for text in sentiment_topic_test_data['text']:\n",
    "    tokens = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    output = model(**tokens)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = expit(scores)\n",
    "    predictions = (scores >= 0.5) * 1\n",
    "    \n",
    "    # Map predictions to classes\n",
    "    predicted_labels = [class_mapping[i] for i in range(len(predictions)) if predictions[i]]\n",
    "    predicted_topics.append(predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db994a16-ae9a-4613-a513-bed0d76488d4",
   "metadata": {},
   "source": [
    "### 3.1.1 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1372c0bd-da6f-43e3-98c4-6c445b16feaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  I wouldn't be caught dead watching the NFL if ...   \n",
      "1  Chris O'Donnell stated that while filming for ...   \n",
      "2  The whole game was a rollercoaster ride, but L...   \n",
      "3  Zendaya slayed in Dune 2, as she does in all h...   \n",
      "4  While my favorite player was playing this matc...   \n",
      "5  My uncle's brother's neighbor's cat's veterina...   \n",
      "6  He said that The Great Gatsby is the best nove...   \n",
      "7  I could not look away from this train wrck of ...   \n",
      "8  The film Everything Everywhere All At Once fol...   \n",
      "9  I just finished reading pride and prejudice wh...   \n",
      "\n",
      "                                predicted_topics  \n",
      "0                                       [sports]  \n",
      "1     [celebrity_&_pop_culture, film_tv_&_video]  \n",
      "2                                       [sports]  \n",
      "3     [celebrity_&_pop_culture, film_tv_&_video]  \n",
      "4                                       [sports]  \n",
      "5  [diaries_&_daily_life, news_&_social_concern]  \n",
      "6     [celebrity_&_pop_culture, film_tv_&_video]  \n",
      "7        [diaries_&_daily_life, film_tv_&_video]  \n",
      "8     [celebrity_&_pop_culture, film_tv_&_video]  \n",
      "9                        [news_&_social_concern]  \n"
     ]
    }
   ],
   "source": [
    "sentiment_topic_test_data['predicted_topics'] = predicted_topics\n",
    "\n",
    "print(sentiment_topic_test_data[['text', 'predicted_topics']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb74b58-280f-48e2-a37d-82fcf9cd52aa",
   "metadata": {},
   "source": [
    "### 3.2 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a8c70bb5-c95d-4eec-b6ae-7acb60472a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/ilyas/.cache/huggingface/datasets/valurank___csv/valurank--Topic_Classification-31f87df3854a46bd/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ae91fecec74660a55ab2a57131151a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\ilyas\\.cache\\huggingface\\datasets\\valurank___csv\\valurank--Topic_Classification-31f87df3854a46bd\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-02e088ba313b0923.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22462 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "naive_bayes_dataset = load_dataset(\"valurank/Topic_Classification\")\n",
    "\n",
    "# Remove None values\n",
    "naive_bayes_dataset['train'] = naive_bayes_dataset['train'].filter(lambda example: example['article_text'] is not None)\n",
    "\n",
    "# Apply preprocessing\n",
    "naive_bayes_dataset['train'] = naive_bayes_dataset['train'].map(lambda x: {'article_text': preprocess_text(x['article_text'])})\n",
    "\n",
    "train_data, validation_data = train_test_split(naive_bayes_dataset['train'], test_size=0.1, random_state=42)\n",
    "\n",
    "X_train = train_data['article_text']\n",
    "y_train = train_data['topic']\n",
    "X_val = validation_data['article_text']\n",
    "y_val = validation_data['topic']\n",
    "\n",
    "X_test = sentiment_topic_test_data['text'].apply(preprocess_text)\n",
    "y_test = sentiment_topic_test_data['topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "478174cb-343a-4b43-a2f6-5388f58ab865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nb_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Train the Naive Bayes model\n",
    "nb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred = nb_pipeline.predict(X_val)\n",
    "y_test_pred = nb_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60107be8-79f5-41bc-9c5a-da2dc294ea39",
   "metadata": {},
   "source": [
    "### 3.2.1 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa7874fe-3e0c-4107-8b4a-9cc144b41af7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  I wouldn't be caught dead watching the NFL if ...   \n",
      "1  Chris O'Donnell stated that while filming for ...   \n",
      "2  The whole game was a rollercoaster ride, but L...   \n",
      "3  Zendaya slayed in Dune 2, as she does in all h...   \n",
      "4  While my favorite player was playing this matc...   \n",
      "5  My uncle's brother's neighbor's cat's veterina...   \n",
      "6  He said that The Great Gatsby is the best nove...   \n",
      "7  I could not look away from this train wrck of ...   \n",
      "8  The film Everything Everywhere All At Once fol...   \n",
      "9  I just finished reading pride and prejudice wh...   \n",
      "\n",
      "              predicted_sentiment  \n",
      "0                        Football  \n",
      "1                          Movies  \n",
      "2                      Basketball  \n",
      "3                       Celebrity  \n",
      "4                        Football  \n",
      "5  Extreme Weather and Cataclysms  \n",
      "6                        Football  \n",
      "7  Extreme Weather and Cataclysms  \n",
      "8  Extreme Weather and Cataclysms  \n",
      "9  Extreme Weather and Cataclysms  \n"
     ]
    }
   ],
   "source": [
    "sentiment_topic_test_data['predicted_sentiment'] = y_test_pred\n",
    "\n",
    "print(sentiment_topic_test_data[['text', 'predicted_sentiment']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
